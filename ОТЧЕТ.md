# Отчет по проекту "Аналитическая платформа повторных госпитализаций пациентов с диабетом"

## 1. Введение

### 1.1. Цель проекта

Проект направлен на создание аналитической платформы для исследования факторов, влияющих на повторные госпитализации пациентов с диабетом. Платформа позволяет собирать, анализировать данные и прогнозировать вероятность повторной госпитализации, что помогает улучшить бизнес-процессы в здравоохранении.

### 1.2. Задачи проекта

1. **Определение области проекта:** Выбрана область здравоохранения, конкретно - анализ повторных госпитализаций пациентов с диабетом
2. **Сбор данных:** Использован публичный датасет о пациентах с диабетом
3. **Очистка данных:** Удалены пропуски, обработаны выбросы, нормализованы данные
4. **Предобработка данных:** Кодирование категориальных признаков, выбор топ-10 признаков
5. **Хранение данных:** Настроена SQLite база данных для хранения обработанных данных
6. **Анализ и визуализация:** Построены графики для выявления зависимостей
7. **Обеспечение качества данных:** Реализована валидация при загрузке данных
8. **Презентация результатов:** Создан веб-интерфейс для работы с платформой

## 2. Описание домена и бизнес-проблемы

### 2.1. Домен: Здравоохранение

Выбрана область здравоохранения, так как:
- Высокая социальная значимость
- Большой объем данных для анализа
- Возможность улучшения качества медицинской помощи
- Экономическая эффективность (снижение повторных госпитализаций)

### 2.2. Бизнес-проблема

**Проблема:** Высокая частота повторных госпитализаций пациентов с диабетом приводит к:
- Увеличению нагрузки на медицинские учреждения
- Росту затрат на здравоохранение
- Ухудшению качества жизни пациентов
- Неэффективному использованию ресурсов

**Решение:** Создание платформы для:
- Анализа факторов риска повторных госпитализаций
- Прогнозирования вероятности повторной госпитализации
- Принятия обоснованных решений для профилактики

## 3. Сбор данных

### 3.1. Источники данных

Использован публичный датасет о пациентах с диабетом, содержащий информацию о:
- Демографических данных пациентов
- Медицинских диагнозах
- Количестве визитов (стационарных, амбулаторных, экстренных)
- Медицинских специальностях
- Приеме препаратов
- Исходах госпитализаций (повторные госпитализации)

### 3.2. Структура исходных данных

Исходный датасет содержит более 50 признаков, включая:
- Числовые признаки (количество визитов, диагнозов и т.д.)
- Категориальные признаки (диагнозы, специальности, препараты)
- Целевой признак (readmitted: NO, <30, >30)

## 4. Очистка данных

### 4.1. Обнаруженные проблемы

1. **Пропуски в данных:**
   - Категориальные признаки: заполнены модой
   - Числовые признаки: заполнены медианой
   - Целевой признак: строки с пропусками удалены

2. **Работа с выбросами:**
   - Проанализированы выбросы в каждом столбце
   - Выбросов мало (менее 5%) и они не слишком далеки от основной массы значений. Решено их оставить

### 4.2. Процесс очистки

**Файл:** `src/data_processing/preprocess.py`

**Этапы:**
1. Загрузка исходных данных
2. Анализ пропусков
3. Удаление строк с пропусками в целевом признаке
4. Заполнение пропусков в категориальных признаках модой
5. Заполнение пропусков в числовых признаках медианой
6. Сохранение очищенных данных

**Результат:** Получен датасет без пропусков в критических признаках

## 5. Предобработка данных

### 5.1. Выбор признаков

**Файл:** `src/data_processing/select_top_features.py`

На основе анализа корреляций и важности признаков выбраны топ-10 признаков:

**Числовые (5):**
- `number_inpatient` - количество стационарных визитов
- `number_diagnoses` - количество диагнозов
- `number_emergency` - количество экстренных визитов
- `number_outpatient` - количество амбулаторных визитов
- `time_in_hospital` - время в больнице (дни)

**Категориальные (5):**
- `diag_1` - основной диагноз
- `diag_2` - второй диагноз
- `diag_3` - третий диагноз
- `medical_specialty` - медицинская специальность лечащего врача
- `diabetesMed` - прием диабетических препаратов

**Целевой:**
- `readmitted` - повторная госпитализация

### 5.2. Кодирование данных

Для моделей машинного обучения созданы две версии данных:
1. **Без кодирования** (`diabetic_data_top10.csv`) - для хранения в БД
2. **С кодированием** (`diabetic_data_top10_encoded.csv`) - для обучения моделей (One-Hot Encoding)

## 6. Хранение данных

### 6.1. Выбор хранилища

Выбрана **SQLite** база данных по следующим причинам:
- Легковесность
- Не требует отдельного сервера
- Достаточна для проекта
- Простота развертывания

### 6.2. Структура базы данных

**Файл:** `src/data_processing/models.py`

**Таблица:** `diabetic_data_top10.csv`

**Модель SQLAlchemy:** `PatientTop10`

**Поля:**
- `id` (Integer, Primary Key) - уникальный идентификатор
- Числовые поля (Integer): number_inpatient, number_diagnoses, number_emergency, number_outpatient, time_in_hospital
- Категориальные поля (String): diag_1, diag_2, diag_3, medical_specialty, diabetesMed
- Целевой признак (String): readmitted

### 6.3. Инициализация БД

**Файл:** `src/data_processing/database.py`

**Функция:** `init_db()`

**Процесс:**
1. Создание таблиц (если не существуют)
2. Проверка наличия данных
3. Если БД пустая - загрузка начальных данных из CSV файла
4. Автоматическая инициализация при первом использовании

## 7. API и роуты

### 7.1. Архитектура API

**Файл:** `src/api/app.py`

**Технология:** FastAPI

**Особенности:**
- Автоматическая документация (Swagger)
- CORS middleware для работы с фронтендом
- Глобальная обработка ошибок
- Валидация данных через Pydantic

### 7.2. Роут загрузки данных

**Файл:** `src/api/routes/upload_data.py`

**Endpoint:** `POST /data/upload`

**Функциональность:**
1. Принимает CSV файл
2. Валидирует данные:
   - Проверка наличия всех обязательных столбцов
   - Проверка отсутствия пропусков
3. Добавляет данные в БД (к существующим данным)
4. Возвращает статистику загрузки

**Валидация:**
- Все столбцы из топ-10 признаков + readmitted должны присутствовать
- Все значения должны быть заполнены (без пропусков)
- При ошибке валидации возвращается детальное сообщение

**Обработка ошибок:**
- Ошибки чтения файла
- Ошибки валидации
- Ошибки записи в БД
- Все ошибки возвращаются с понятными сообщениями

### 7.3. Роут предсказания

**Файл:** `src/api/routes/predict.py`

**Endpoint:** `POST /model/predict`

**Функциональность:**
1. Принимает данные пациента (JSON)
2. Проверяет наличие всех признаков
3. Выполняет предсказание с помощью модели CatBoost
4. Возвращает прогноз и вероятность

**Модель:** CatBoost (загружается из `models/catboost_top10.pkl`)

**Обработка ошибок:**
- Проверка наличия всех признаков
- Обработка ошибок модели
- Валидация типов данных

### 7.4. Роуты дашборда

**Файл:** `src/api/routes/dashboard.py`

**Endpoints:**
- `GET /dashboard/stats` - общая статистика
- `GET /dashboard/chart?chart_type={type}` - получение графика
- `GET /dashboard/charts/list` - список доступных графиков

**Функциональность статистики:**
- Количество записей в БД
- Процент повторных госпитализаций
- Количество с/без повторной госпитализации

**Функциональность графиков:**
- Загрузка данных из БД
- Построение графиков с помощью Matplotlib/Seaborn
- Возврат графиков в формате base64

**Обработка ошибок:**
- Проверка наличия данных в БД
- Валидация типа графика
- Обработка ошибок построения графиков

## 8. Визуализации

### 8.1. Функции визуализации

**Файл:** `src/api/utils/visualizations.py`

**Библиотеки:** Matplotlib, Seaborn

### 8.2. Типы графиков

#### График 1: Зависимость от количества диагнозов

**Функция:** `create_readmission_by_diagnoses_chart()`

**Тип:** Столбчатая диаграмма

**Описание:**
- Группирует данные по количеству диагнозов
- Вычисляет процент повторных госпитализаций для каждой группы
- Показывает зависимость между количеством диагнозов и риском повторной госпитализации

**Инсайты:**
- Позволяет выявить, как количество диагнозов влияет на вероятность повторной госпитализации
- Помогает понять, является ли множественность диагнозов фактором риска

#### График 2: Зависимость от стационарных визитов

**Функция:** `create_readmission_by_inpatient_visits_chart()`

**Тип:** Линейный график с заливкой

**Описание:**
- Группирует данные по количеству стационарных визитов
- Вычисляет процент повторных госпитализаций
- Показывает тренд зависимости

**Инсайты:**
- Выявляет связь между частотой стационарных визитов и повторными госпитализациями
- Помогает понять, является ли частота визитов индикатором риска

#### График 3: Зависимость от приема препаратов

**Функция:** `create_readmission_by_diabetes_med_chart()`

**Тип:** Комбинированный (столбчатая и круговая диаграммы)

**Описание:**
- Сравнивает пациентов с приемом и без приема диабетических препаратов
- Показывает распределение исходов (NO, <30, >30) для каждой группы
- Включает круговую диаграмму для детального анализа группы "Yes"

**Инсайты:**
- Выявляет влияние приема препаратов на вероятность повторной госпитализации
- Помогает оценить эффективность медикаментозного лечения

### 8.3. Технические детали визуализаций

- Использование стиля 'seaborn-v0_8-darkgrid' для единообразия
- Размеры фигур оптимизированы для веб-отображения
- Сохранение в формате PNG с высоким разрешением (100 DPI)
- Кодирование в base64 для передачи через API
- Автоматическое закрытие фигур для освобождения памяти

## 9. Фронтенд

### 9.1. Технология

**Файл:** `frontend/app.py`

**Технология:** Streamlit

**Причины выбора:**
- Простота разработки
- Встроенные компоненты для работы с данными
- Быстрое создание интерактивного интерфейса
- Интеграция с Python экосистемой

### 9.2. Структура интерфейса

#### Раздел 1: Дашборд

**Функциональность:**
- Отображение статистики (метрики)
- Выбор типа графика из выпадающего списка
- Построение и отображение графиков
- Показ данных графика в развернутом виде

**Особенности:**
- Асинхронная загрузка данных
- Обработка ошибок подключения к API
- Визуальная обратная связь (спиннеры, сообщения)

#### Раздел 2: Предсказание

**Функциональность:**
- Форма ввода данных пациента
- Разделение на числовые и категориальные поля
- Валидация данных перед отправкой
- Отображение результатов с интерпретацией

**Особенности:**
- Подсказки для полей ввода
- Цветовая индикация результатов
- Метрики для вероятности

#### Раздел 3: Загрузка данных

**Функциональность:**
- Загрузка CSV файлов
- Отображение требований к файлу
- Валидация и загрузка в БД
- Отображение результатов загрузки

**Особенности:**
- Информационные блоки с требованиями
- Обработка ошибок валидации
- Статистика загруженных данных

#### Раздел 4: О проекте

**Функциональность:**
- Описание проекта
- Информация о признаках
- Проверка подключения к API

### 9.3. Обработка ошибок на фронтенде

**Функция:** `make_api_request()`

**Обрабатываемые ошибки:**
- Ошибки подключения (ConnectionError)
- Таймауты (Timeout)
- HTTP ошибки (HTTPError)
- Неожиданные ошибки

**Особенности:**
- Понятные сообщения об ошибках для пользователя
- Визуальная индикация ошибок
- Логирование для отладки

### 9.4. Дизайн

**CSS стили:**
- Кастомные стили для заголовков
- Информационные блоки
- Блоки успеха и ошибок
- Адаптивная верстка

**Компоненты:**
- Метрики (st.metric)
- Колонки (st.columns)
- Выпадающие списки (st.selectbox)
- Кнопки с типами (primary, secondary)
- Развертываемые блоки (st.expander)

## 10. Модель машинного обучения

### 10.1. Выбор модели

**Модель:** CatBoost

**Причины выбора:**
- Отличная работа с категориальными признаками
- Высокая точность
- Устойчивость к переобучению

### 10.2. Обучение модели

**Файл:** `src/modeling/train_model.py`

**Параметры:**
- iterations: 300
- depth: 6
- learning_rate: 0.1
- loss_function: "MultiClass"

**Данные:**
- Используются топ-10 признаков
- Категориальные признаки передаются как строки
- Целевая переменная: readmitted (NO, <30, >30)

### 10.3. Использование модели

**Файл:** `src/modeling/predict.py`

**Процесс:**
1. Загрузка модели при импорте модуля
2. Преобразование входных данных в DataFrame
3. Приведение категориальных признаков к строковому типу
4. Выполнение предсказания
5. Возврат результата и вероятности

## 11. Обеспечение качества данных

### 11.1. Валидация при загрузке

**Файл:** `src/api/routes/upload_data.py`

**Функция:** `validate_data()`

**Проверки:**
1. Наличие всех обязательных столбцов
2. Отсутствие пропусков в данных
3. Корректность типов данных

**Результат:**
- При ошибке валидации данные не загружаются
- Возвращается детальное сообщение об ошибке
- Указываются конкретные проблемы

### 11.2. Метрики качества

**Метрики, отслеживаемые в проекте:**
- Количество записей в БД
- Процент повторных госпитализаций
- Распределение по классам целевой переменной

### 11.3. Автоматизированные проверки

- Валидация при каждой загрузке данных
- Проверка наличия данных перед построением графиков
- Проверка наличия признаков перед предсказанием

## 12. Описание каждого файла проекта

### 12.1. API файлы

#### `src/api/app.py`
**Назначение:** Главный файл FastAPI приложения
**Функции:**
- Инициализация приложения
- Настройка CORS
- Подключение роутов
- Глобальная обработка ошибок
- Корневой endpoint

#### `src/api/routes/dashboard.py`
**Назначение:** Роуты для дашборда
**Функции:**
- `stats()` - получение статистики
- `get_chart()` - получение графика по типу
- `list_charts()` - список доступных графиков

#### `src/api/routes/predict.py`
**Назначение:** Роуты для предсказаний
**Функции:**
- `predict_route()` - выполнение предсказания
- Валидация входных данных
- Обработка ошибок

#### `src/api/routes/upload_data.py`
**Назначение:** Роуты для загрузки данных
**Функции:**
- `upload()` - загрузка и валидация данных
- `validate_data()` - валидация данных
- Добавление данных в БД

#### `src/api/utils/visualizations.py`
**Назначение:** Функции для построения графиков
**Функции:**
- `create_readmission_by_diagnoses_chart()` - график по диагнозам
- `create_readmission_by_inpatient_visits_chart()` - график по визитам
- `create_readmission_by_diabetes_med_chart()` - график по препаратам

### 12.2. Файлы обработки данных

#### `src/data_processing/database.py`
**Назначение:** Работа с базой данных
**Функции:**
- Создание engine и session
- `init_db()` - инициализация БД и загрузка начальных данных

#### `src/data_processing/models.py`
**Назначение:** Модели SQLAlchemy
**Классы:**
- `PatientTop10` - модель для таблицы с топ-10 признаками

#### `src/data_processing/load_data.py`
**Назначение:** Загрузка данных
**Функции:**
- `load_processed()` - загрузка из CSV (для обратной совместимости)
- `load_top10_from_db()` - загрузка из БД

#### `src/data_processing/preprocess.py`
**Назначение:** Предобработка исходных данных
**Функции:**
- `preprocess()` - полный цикл предобработки
- Очистка данных
- Заполнение пропусков
- Сохранение схемы

#### `src/data_processing/select_top_features.py`
**Назначение:** Выбор топ-10 признаков
**Функции:**
- `main()` - выбор признаков и сохранение таблиц
- Создание версий с кодированием и без

#### `src/data_processing/schema.py`
**Назначение:** Работа со схемой данных
**Функции:**
- `save_schema()` - сохранение схемы в JSON
- `load_schema()` - загрузка схемы

### 12.3. Файлы моделирования

#### `src/modeling/train_model.py`
**Назначение:** Обучение моделей
**Функции:**
- `train()` - обучение CatBoost модели
- `evaluate_model()` - оценка качества (внутри train_model.py)

#### `src/modeling/predict.py`
**Назначение:** Выполнение предсказаний
**Функции:**
- `predict_one()` - предсказание для одного пациента
- Загрузка модели
- Преобразование данных

### 12.4. Файлы анализа

#### `src/analysis/data_analysis.py`
**Назначение:** Анализ данных
**Функции:** Различные аналитические функции

#### `src/analysis/feature_correlation.py`
**Назначение:** Анализ корреляций признаков
**Функции:** Вычисление корреляций для выбора признаков

### 12.5. Фронтенд

#### `frontend/app.py`
**Назначение:** Веб-интерфейс приложения
**Функции:**
- Все разделы интерфейса
- `make_api_request()` - универсальная функция для API запросов
- Обработка ошибок
- Визуализация данных

## 13. Результаты и выводы

### 13.1. Достигнутые результаты

1. **Создана полнофункциональная платформа:**
   - API с валидацией и обработкой ошибок
   - Веб-интерфейс с интуитивным дизайном
   - База данных для хранения данных
   - Система визуализации

2. **Реализована обработка данных:**
   - Очистка и предобработка
   - Выбор значимых признаков
   - Валидация при загрузке

3. **Созданы аналитические инструменты:**
   - 3 типа графиков для анализа зависимостей
   - Статистические метрики
   - Прогнозирование

4. **Обеспечено качество:**
   - Строгая валидация данных
   - Обработка ошибок на всех уровнях
   - Информативные сообщения

### 13.2. Выявленные инсайты

1. **Количество диагнозов** влияет на вероятность повторной госпитализации
2. **Частота стационарных визитов** коррелирует с повторными госпитализациями
3. **Прием диабетических препаратов** может влиять на исходы

### 13.3. Рекомендации

1. **Для медицинских учреждений:**
   - Использовать платформу для мониторинга пациентов группы риска
   - Применять прогнозы для планирования ресурсов
   - Анализировать факторы риска для профилактики

2. **Для дальнейшего развития:**
   - Добавить больше типов графиков
   - Расширить функционал анализа
   - Улучшить модель машинного обучения
   - Добавить экспорт отчетов
   - Жополнительно проработать признаки

3. **Для качества данных:**
   - Регулярная валидация загружаемых данных
   - Мониторинг качества данных в БД
   - Автоматические проверки целостности

## 14. Заключение

Проект успешно реализован и включает все необходимые компоненты аналитической платформы:
- Сбор и хранение данных
- Очистка и предобработка
- Анализ и визуализация
- Прогнозирование
- Веб-интерфейс

Платформа может быть использована для улучшения бизнес-процессов в здравоохранении за счет анализа данных и прогнозирования повторных госпитализаций.

## 15. Технические детали реализации

### 15.1. Зависимости проекта

Все зависимости указаны в `requirements.txt`:
- FastAPI, Uvicorn - веб-фреймворк и сервер
- Pandas, NumPy - обработка данных
- SQLAlchemy - работа с БД
- CatBoost, scikit-learn - машинное обучение
- Matplotlib, Seaborn - визуализация
- Streamlit - фронтенд
- Requests - HTTP клиент

### 15.2. Структура базы данных

База данных SQLite хранит только топ-10 признаков + целевой признак для оптимизации:
- Размер БД
- Скорость запросов
- Простота управления

### 15.3. Безопасность

- Валидация всех входных данных
- Обработка ошибок на всех уровнях
- Защита от SQL-инъекций (через ORM)
- CORS настройки для безопасности

### 15.4. Производительность

- Загрузка модели один раз при старте
- Использование bulk операций для БД
- Кэширование данных где возможно
- Оптимизация запросов к БД

---

**Дата создания отчета:** 2024
**Версия проекта:** 1.0.0

